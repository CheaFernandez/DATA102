{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a524ee64",
   "metadata": {},
   "source": [
    "Scrape any website using BeautifulSoup or Selenium. If possible, you might want to start collecting data for the project that you have in mind. Your data must have the following specifications at the very least:\n",
    "\n",
    "Data points: 100\n",
    "Features: 5\n",
    "\n",
    "You can add some metadata present on the page if what you have is not enough. In 5 minutes, present in class how you did your scraping. You may use the following as your guideline:\n",
    "\n",
    "Why did you choose to scrape this site?\n",
    "What were the challenges you encountered?\n",
    "You may go through your notebook.\n",
    "Do you think that the data you collected contains personally identifiable information (PII)?\n",
    "Any other learning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "c5d958b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install selenium\n",
    "# %pip install webdriver_manager\n",
    "# %pip install --upgrade webdriver_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "bb18d90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41c5535",
   "metadata": {},
   "source": [
    "First, let's initialize the Selenium webdriver. **You can either change the chromedriver_path to the path of your local chrome driver or use ChromeDriverManager**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "141320df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chromedriver_path = \"./chromedriver-mac-x64/chromedriver\"\n",
    "# service = Service(chromedriver_path)\n",
    "\n",
    "# driver = webdriver.Chrome(service=service)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "15aadd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad1e4ca",
   "metadata": {},
   "source": [
    "## Scraping from a single thread"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984b76ba",
   "metadata": {},
   "source": [
    "Let's try to scrape one of the the latest Makeup Discussion Threads from a subreddit, `r/beautytalkph`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "21199620",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "url = \"https://www.reddit.com/r/beautytalkph/comments/1cy3t0z/makeup_thread_may_23_2024/?rdt=65047\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7b33cd",
   "metadata": {},
   "source": [
    "When we first open the page, we can scroll down to the bottom of the page to trigger the lazy loading to render the next batch of comments. Though at a certain point, Reddit will stop fetching for more comments once we scroll far enough. To view the rest of the comments, we have to click on a \"View more comments\" button. \n",
    "\n",
    "The script below handles both cases, and continues this process of loading more comments until we reach the last comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "9c828a41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scrolled to bottom...\n",
      "More content loaded...\n",
      "Scrolled to bottom...\n",
      "Clicked \"View more\"...\n",
      "More content loaded...\n",
      "Scrolled to bottom...\n",
      "Clicked \"View more\"...\n",
      "More content loaded...\n",
      "Scrolled to bottom...\n",
      "Clicked \"View more\"...\n",
      "More content loaded...\n",
      "Scrolled to bottom...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "def scroll_to_bottom(driver):\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    while True:\n",
    "        # First, check for \"View more comments\" button\n",
    "        page_buttons = driver.find_elements(By.XPATH, \"//button[@rpl]\")\n",
    "        btn_matches_found = [btn for btn in page_buttons if btn.text == \"View more comments\"]\n",
    "\n",
    "        # Scroll to bottom to view more comments\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        print(\"Scrolled to bottom...\")\n",
    "\n",
    "        # If \"View more comments\" was found, click to view more comments\n",
    "        if len(btn_matches_found) > 0:\n",
    "            view_more_comments_btn = btn_matches_found[0]\n",
    "            view_more_comments_btn.click()\n",
    "            print(\"Clicked \\\"View more\\\"...\")\n",
    "\n",
    "        # Wait for a few seconds before checking if new content has loaded\n",
    "        time.sleep(random.uniform(4, 8))\n",
    "\n",
    "        # Check if new content has loaded by checking the \"height\" of the page\n",
    "        current_page_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "        if current_page_height == last_height:\n",
    "            print(\"Done.\")\n",
    "            break\n",
    "        else:\n",
    "            last_height = current_page_height\n",
    "            print(\"More content loaded...\")\n",
    "\n",
    "# Call the function\n",
    "scroll_to_bottom(driver)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cd8df2",
   "metadata": {},
   "source": [
    "By looking at the HTML through our own browser, we can see that each comment in the thread is represented by a `<shreddit-comment>` tag. The tag contains some notable attributes, such as the comment's id and author, and we can get other kinds of data within the children of the tag, such as the date and time the comment was created and the comment content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "5f8c8e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_comments(driver):\n",
    "    df_comments = pd.DataFrame(columns=[\n",
    "        \"comment_id\",\n",
    "        \"author\",\n",
    "        \"text\",\n",
    "        \"score\",\n",
    "        \"depth\",\n",
    "        \"parent_comment_id\",\n",
    "        \"thread_id\",\n",
    "        \"date_created\"\n",
    "    ])\n",
    "    \n",
    "    comments = driver.find_elements(By.XPATH, \"//shreddit-comment\")\n",
    "\n",
    "    for comment_div in comments:\n",
    "        comment_id = comment_div.get_attribute(\"thingid\")\n",
    "        author = comment_div.get_attribute(\"author\")\n",
    "        text = comment_div.find_element(By.XPATH, \".//div[@slot='comment']\").text\n",
    "        score = comment_div.get_attribute(\"score\")\n",
    "        depth = comment_div.get_attribute(\"depth\")\n",
    "        parent_comment_id = comment_div.get_attribute(\"parentid\")\n",
    "        thread_id = comment_div.get_attribute(\"postid\")\n",
    "        date_created = comment_div.find_element(By.XPATH, \".//time\").get_attribute(\"datetime\")\n",
    "        \n",
    "        new_row_data = {\n",
    "            'comment_id': comment_id,\n",
    "            'author': author,\n",
    "            'text': text,\n",
    "            'score': score,\n",
    "            'depth': depth,\n",
    "            'parent_comment_id': parent_comment_id,\n",
    "            'thread_id': thread_id,\n",
    "            'date_created': date_created\n",
    "        }\n",
    "\n",
    "        new_row_df = pd.DataFrame([new_row_data])\n",
    "        \n",
    "        df_comments = pd.concat([df_comments, new_row_df], ignore_index=True)\n",
    "    \n",
    "    return df_comments\n",
    "\n",
    "# Call the function\n",
    "df_comments = extract_comments(driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "338586b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "219"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efb5d02",
   "metadata": {},
   "source": [
    "### Looping Multiple Threads\n",
    "\n",
    "Now let's open the subreddit r/beautytalkph, specifically targeting threads tagged with \"Makeup Weekly Thread\". Let's get the links to the first three threads as these threads are not affected by the Shadow DOM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "0de34101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.reddit.com/r/beautytalkph/comments/1d77yqa/makeup_thread_june_04_2024/', 'https://www.reddit.com/r/beautytalkph/comments/1d3fosr/makeup_thread_may_30_2024/', 'https://www.reddit.com/r/beautytalkph/comments/1d1uvhe/makeup_thread_may_28_2024/']\n"
     ]
    }
   ],
   "source": [
    "# Open the r/beatuytalkph subreddit threads\n",
    "url = \"https://www.reddit.com/r/beautytalkph/?f=flair_name%3A%22Makeup%20Weekly%20Thread%22\"\n",
    "driver.get(url)\n",
    "\n",
    "# Get the links to the top 3 threads\n",
    "n = 3\n",
    "thread_links = []\n",
    "\n",
    "# Define the XPath for the specific <a> element\n",
    "specific_xpath = \"//a[@slot='full-post-link']\"\n",
    "\n",
    "# Find the <a> elements using the XPath\n",
    "elements = driver.find_elements(By.XPATH, specific_xpath)\n",
    "\n",
    "# Extract the href attributes and store them in the array\n",
    "for element in elements[:n]:  # Only process the first 3 elements\n",
    "    link = element.get_attribute('href')\n",
    "    thread_links.append(link)\n",
    "\n",
    "# Print the extracted href attributes\n",
    "print(thread_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d22323",
   "metadata": {},
   "source": [
    "### TODO: Get past the Shadow DOM to get the other links (If we need more links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "3594da3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Get the href links of the threads\n",
    "# shadow_root = driver.find_element(By.XPATH, \"//*[@id=\\\"main-content\\\"]/div[2]/faceplate-batch\").shadow_root\n",
    "# shadow_element = shadow_root.find_element(By.XPATH, \"//*[@id=\\\"faceplate_1\\\"]\")\n",
    "# print(link)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46184348",
   "metadata": {},
   "source": [
    "### Visit each of the links and scrape the comments\n",
    "\n",
    "After collecting the links, let's visit them one by one and scrape the comments in each thread by calling the functions scroll_to_bottom and extract_comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "467b2904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visiting  https://www.reddit.com/r/beautytalkph/comments/1d77yqa/makeup_thread_june_04_2024/\n",
      "Scrolled to bottom...\n",
      "More content loaded...\n",
      "Scrolled to bottom...\n",
      "Clicked \"View more\"...\n",
      "More content loaded...\n",
      "Scrolled to bottom...\n",
      "Clicked \"View more\"...\n",
      "More content loaded...\n",
      "Scrolled to bottom...\n",
      "Clicked \"View more\"...\n",
      "More content loaded...\n",
      "Scrolled to bottom...\n",
      "Done.\n",
      "Comments extracted:  211\n",
      "Visiting  https://www.reddit.com/r/beautytalkph/comments/1d3fosr/makeup_thread_may_30_2024/\n",
      "Scrolled to bottom...\n",
      "More content loaded...\n",
      "Scrolled to bottom...\n",
      "Clicked \"View more\"...\n",
      "More content loaded...\n",
      "Scrolled to bottom...\n",
      "Clicked \"View more\"...\n",
      "More content loaded...\n",
      "Scrolled to bottom...\n",
      "Clicked \"View more\"...\n",
      "More content loaded...\n",
      "Scrolled to bottom...\n",
      "Clicked \"View more\"...\n",
      "More content loaded...\n",
      "Scrolled to bottom...\n",
      "Done.\n",
      "Comments extracted:  312\n",
      "Visiting  https://www.reddit.com/r/beautytalkph/comments/1d1uvhe/makeup_thread_may_28_2024/\n",
      "Scrolled to bottom...\n",
      "More content loaded...\n",
      "Scrolled to bottom...\n",
      "Clicked \"View more\"...\n",
      "More content loaded...\n",
      "Scrolled to bottom...\n",
      "Clicked \"View more\"...\n",
      "More content loaded...\n",
      "Scrolled to bottom...\n",
      "Done.\n",
      "Comments extracted:  146\n",
      "Total comments extracted:  888\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "for link in thread_links:\n",
    "    driver.get(link)\n",
    "    # Check if driver got the link\n",
    "    print(\"Visiting \", driver.current_url)\n",
    "\n",
    "    # Wait for the comments to load\n",
    "    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, \"//shreddit-comment\")))\n",
    "    \n",
    "    # Scroll to the bottom of the page\n",
    "    scroll_to_bottom(driver)\n",
    "    \n",
    "    # Get the comments\n",
    "    comments = extract_comments(driver)\n",
    "    print(\"Comments extracted: \", len(comments))\n",
    "\n",
    "    # Append the comments to the all_comments DataFrame\n",
    "    df_comments = pd.concat([df_comments, comments], ignore_index=True)\n",
    "\n",
    "print(\"Total comments extracted: \", len(df_comments))\n",
    "print(\"Done\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "82b9af67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "      <th>depth</th>\n",
       "      <th>parent_comment_id</th>\n",
       "      <th>thread_id</th>\n",
       "      <th>date_created</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t1_l76ljn8</td>\n",
       "      <td>tonychoppa513</td>\n",
       "      <td>Hi I'm a guy and been wanting to use beauty pr...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>1cy3t0z</td>\n",
       "      <td>2024-06-05T06:34:56.870Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t1_l6et4jq</td>\n",
       "      <td>hlg64</td>\n",
       "      <td>For those who use skincare products, facial an...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>1cy3t0z</td>\n",
       "      <td>2024-05-31T01:14:27.261Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t1_l60t8zd</td>\n",
       "      <td>beefymademoiselle</td>\n",
       "      <td>Any recs for red blushes for light medium w/ n...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>1cy3t0z</td>\n",
       "      <td>2024-05-28T13:32:12.778Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t1_l5wpz8f</td>\n",
       "      <td>Dear_Elephant7549</td>\n",
       "      <td>i need a compact brow product reco po! i'm onl...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>1cy3t0z</td>\n",
       "      <td>2024-05-27T17:26:00.782Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t1_l6lehui</td>\n",
       "      <td>sunnyisloved</td>\n",
       "      <td>not a powder girly, but I know strokes release...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>t1_l5wpz8f</td>\n",
       "      <td>1cy3t0z</td>\n",
       "      <td>2024-06-01T07:36:15.586Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>t1_l65h2lw</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>Repost on hair care thread po ☺️</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2024-05-29T09:38:36.607Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>t1_l65x4ly</td>\n",
       "      <td>sarcastronaughty</td>\n",
       "      <td>Repost on hair care thread po ☺️</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>t1_l65h2lw</td>\n",
       "      <td>t3_1d1uvhe</td>\n",
       "      <td>2024-05-29T12:16:05.570Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>t1_l628arj</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>This belongs in the Seller’s Thread!</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2024-05-28T18:42:20.725Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>t1_l63ucg8</td>\n",
       "      <td>cmr82</td>\n",
       "      <td>This belongs in the Seller’s Thread!</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>t1_l628arj</td>\n",
       "      <td>t3_1d1uvhe</td>\n",
       "      <td>2024-05-29T00:41:51.631Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>t1_l630viz</td>\n",
       "      <td>sarcastronaughty</td>\n",
       "      <td>Are you a warm undertone?</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>t1_l628arj</td>\n",
       "      <td>t3_1d1uvhe</td>\n",
       "      <td>2024-05-28T21:29:21.688Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>888 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     comment_id             author  \\\n",
       "0    t1_l76ljn8      tonychoppa513   \n",
       "1    t1_l6et4jq              hlg64   \n",
       "2    t1_l60t8zd  beefymademoiselle   \n",
       "3    t1_l5wpz8f  Dear_Elephant7549   \n",
       "4    t1_l6lehui       sunnyisloved   \n",
       "..          ...                ...   \n",
       "883  t1_l65h2lw          [deleted]   \n",
       "884  t1_l65x4ly   sarcastronaughty   \n",
       "885  t1_l628arj          [deleted]   \n",
       "886  t1_l63ucg8              cmr82   \n",
       "887  t1_l630viz   sarcastronaughty   \n",
       "\n",
       "                                                  text score depth  \\\n",
       "0    Hi I'm a guy and been wanting to use beauty pr...     1     0   \n",
       "1    For those who use skincare products, facial an...     0     0   \n",
       "2    Any recs for red blushes for light medium w/ n...     2     0   \n",
       "3    i need a compact brow product reco po! i'm onl...     1     0   \n",
       "4    not a powder girly, but I know strokes release...     1     1   \n",
       "..                                                 ...   ...   ...   \n",
       "883                   Repost on hair care thread po ☺️           0   \n",
       "884                   Repost on hair care thread po ☺️     1     1   \n",
       "885               This belongs in the Seller’s Thread!           0   \n",
       "886               This belongs in the Seller’s Thread!     6     1   \n",
       "887                          Are you a warm undertone?     0     1   \n",
       "\n",
       "    parent_comment_id   thread_id              date_created  \n",
       "0                None     1cy3t0z  2024-06-05T06:34:56.870Z  \n",
       "1                None     1cy3t0z  2024-05-31T01:14:27.261Z  \n",
       "2                None     1cy3t0z  2024-05-28T13:32:12.778Z  \n",
       "3                None     1cy3t0z  2024-05-27T17:26:00.782Z  \n",
       "4          t1_l5wpz8f     1cy3t0z  2024-06-01T07:36:15.586Z  \n",
       "..                ...         ...                       ...  \n",
       "883              None        None  2024-05-29T09:38:36.607Z  \n",
       "884        t1_l65h2lw  t3_1d1uvhe  2024-05-29T12:16:05.570Z  \n",
       "885              None        None  2024-05-28T18:42:20.725Z  \n",
       "886        t1_l628arj  t3_1d1uvhe  2024-05-29T00:41:51.631Z  \n",
       "887        t1_l628arj  t3_1d1uvhe  2024-05-28T21:29:21.688Z  \n",
       "\n",
       "[888 rows x 8 columns]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "947f603a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "888"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "86e7f517",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301404f4",
   "metadata": {},
   "source": [
    "### Exporting the Dataframe to a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "fefba60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export data to CSV\n",
    "df_comments.to_csv('comments.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
